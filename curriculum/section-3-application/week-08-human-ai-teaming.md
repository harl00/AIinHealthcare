# Week 8: Human-AI Teaming and Workflow Integration

## Section 3: Application | Learning Outcome 3

**Theme:** Making it work: Integrating AI into clinical practice

**Core Question:** *"How do we govern it?"*

---

## Learning Objectives

By the end of this session, students will be able to:

- Design clinical workflows that optimise human-AI collaboration
- Develop strategies to mitigate automation bias and alert fatigue
- Create training programs for clinical AI users
- Apply human factors principles to AI interface design evaluation

---

## Content

### 8.1 Workflow Integration Principles

**AI as Augmentation vs. Automation**

Choosing the right model for different applications:

| Approach | AI Role | Human Role | Best For |
|----------|---------|------------|----------|
| Augmentation | Provides additional information | Makes all decisions | Complex, uncertain situations |
| Automation | Performs routine tasks | Supervises, handles exceptions | Well-defined, repetitive tasks |
| Hybrid | Varies by situation | Varies by situation | Mixed complexity environments |

**Workflow Analysis**

Understanding current state before introducing AI:
- Task analysis: What do people actually do?
- Information flow: What data moves where?
- Decision points: Where are judgements made?
- Failure modes: Where do things go wrong?

**Integration Points**

Where AI adds value vs. where it creates friction:

*High-value integration points:*
- Information synthesis (gathering scattered data)
- Pattern recognition (seeing what humans miss)
- Consistency (reducing variability)
- Speed (faster than human processing)

*Potential friction points:*
- Decision interruption (breaking cognitive flow)
- Additional steps (increasing task time)
- Conflicting information (creating confusion)
- Trust negotiation (deciding whether to follow AI)

**The Problem of "One More Screen"**

Cognitive load and attention are finite:
- Each new system competes for attention
- Information overload degrades performance
- Integration vs. another standalone application
- Screen time vs. patient time

### 8.2 Mitigating Human-AI Interaction Risks

**Designing for Appropriate Trust**

Neither over-reliance nor under-reliance:
- Clear communication of AI certainty/uncertainty
- Transparency about AI limitations
- Feedback on AI accuracy over time
- Calibration exercises

**Alert Design Principles**

Effective alerts are:
- Infrequent enough to maintain attention
- Salient enough to be noticed
- Specific enough to guide action
- Actionable (clear what to do)

**Alert Fatigue Mitigation**

Strategies:
- Reduce alert volume (tune thresholds)
- Tiered alerting (severity-based)
- Contextual suppression (situation-appropriate)
- Intelligent clustering (related alerts together)
- Regular review of alert performance

**Friction by Design**

Sometimes making things harder improves safety:
- Confirmation steps for high-risk actions
- Requiring acknowledgment of AI uncertainty
- Forcing consideration of alternatives
- Preventing automatic acceptance

**Feedback Loops**

Helping clinicians calibrate their trust:
- Show AI accuracy over time
- Highlight cases where AI was right/wrong
- Enable comparison with own accuracy
- Celebrate appropriate overrides

### 8.3 Training and Competency

**What Clinicians Need to Know**

Essential knowledge for AI users:
- What the AI does and doesn't do
- How confident to be in outputs
- When to trust and when to override
- How to report concerns

Not usually needed:
- Detailed technical architecture
- Programming or data science skills
- Mathematical foundations

**Competency Frameworks**

Components of AI competency:
- Knowledge: Understanding what AI is and how it works (basic)
- Skills: Using specific AI tools effectively
- Attitudes: Appropriate trust, critical evaluation
- Behaviours: Documentation, escalation, reporting

**Training Approaches**

| Approach | Advantages | Disadvantages |
|----------|------------|---------------|
| Classroom/online | Efficient, consistent | Abstract, limited practice |
| Simulation | Realistic practice | Resource-intensive |
| Supervised practice | Real-world learning | Risk, variable quality |
| Peer learning | Accessible, contextual | May propagate misconceptions |

Effective training typically combines approaches.

**Simulation and Scenario-Based Training**

Particularly valuable for:
- Rare but critical AI failures
- Override decision-making
- Workflow integration
- Team communication about AI

**Ongoing Education**

As systems evolve:
- Updates when AI changes
- Refresher training
- Performance feedback
- Learning from incidents

### 8.4 Change Management and Culture

**Addressing Clinician Resistance**

Distinguishing legitimate concerns from technophobia:

*Legitimate concerns to address:*
- Patient safety
- Professional autonomy
- Workflow disruption
- Accountability clarity
- Job security

*Misconceptions to correct:*
- AI will replace clinicians entirely
- AI is always right
- AI is completely untrustworthy
- Nothing can be done to shape AI

**Champions and Early Adopters**

Leveraging informal influence:
- Identify and support champions
- Provide resources and time
- Celebrate successes
- Use peer influence

**Managing Expectations**

Neither overselling nor underselling:
- Realistic benefits and timelines
- Honest about limitations
- Clear about learning curve
- Commitment to address problems

**Building a Learning Culture**

Around AI use:
- Psychological safety to report concerns
- No blame for appropriate AI use decisions
- Open discussion of errors
- Continuous improvement mindset

---

## Aeromedical Thread

### Team Dynamics in Retrieval

**AI Integration with Small Teams**

Aeromedical teams are typically small (2-3 members):
- Clear role allocation including AI
- Communication about AI inputs
- Shared awareness of AI status
- Avoiding heads-down time

**CRM Implications**

Crew Resource Management with AI:
- AI as "team member"
- Speaking up about AI disagreement
- Leadership when AI input conflicts
- Situational awareness including AI

**Different Crew Compositions**

AI needs to work across:
- Doctor-paramedic teams
- Nurse-paramedic teams
- Single-crew configurations
- Varying experience levels

**Training Requirements**

For retrieval workforce:
- Casual and rotational staff challenges
- Maintaining currency
- Simulation opportunities
- Remote delivery options

---

## Learning Activities

### Pre-Class Preparation

1. **Human Factors Reading**
   - Complete assigned reading on human factors in healthcare AI
   - Note principles relevant to your practice

2. **Workflow Observation**
   - Observe and document a clinical workflow in your environment
   - Identify potential AI integration points
   - Note current pain points that AI might address

### In-Class Activities

1. **Workflow Redesign Workshop** (Groups, 40 mins)
   - Groups receive current workflow and AI tool description
   - Design integrated workflow
   - Identify human factors considerations
   - Present and critique

2. **Training Program Design** (Pairs, 30 mins)
   - Design training program for AI tool implementation
   - Include: objectives, methods, assessment, ongoing support
   - Peer review and feedback

3. **Interface Evaluation** (Individual, 20 mins)
   - Evaluate AI interface using human factors checklist
   - Identify strengths and concerns
   - Suggest improvements

### Post-Class Activities

1. **Training Needs Analysis**
   - Complete training needs analysis for selected AI implementation
   - Identify competency requirements
   - Design training approach

---

## Indicative Resources

### Required Reading

- Sittig, D.F., & Singh, H. (2010). A new sociotechnical model for studying health information technology in complex adaptive healthcare systems. *Quality and Safety in Health Care*, 19(Suppl 3), i68-i74.

### Recommended Reading

- Human factors in healthcare AI: selected papers (provided)
- Clinical Education resources on technology-enhanced practice

---

## Session Summary

This week focused on the human and workflow dimensions of AI implementation:

1. Workflow integration requires understanding current practice before introducing AI
2. Human-AI interaction risks can be mitigated through thoughtful design
3. Training should focus on appropriate use, not technical mastery
4. Change management and culture are as important as technology
5. Aeromedical team dynamics create specific integration challenges

**Next Week:** We'll examine what happens after go-liveâ€”monitoring, maintenance, and incident response.
