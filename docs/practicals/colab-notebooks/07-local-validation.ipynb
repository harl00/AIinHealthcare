{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üîç Exercise 7: Local Validation Simulation\n",
        "\n",
        "**Week 7 | AI in Healthcare Curriculum**\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By completing this exercise, you will:\n",
        "\n",
        "- üéØ Understand why local validation is essential before AI deployment\n",
        "- üéØ Validate a \"vendor\" model on local Australian data\n",
        "- üéØ Compare vendor-claimed vs locally-validated performance\n",
        "- üéØ Analyse performance gaps and investigate causes\n",
        "- üéØ Apply a structured go/no-go decision framework\n",
        "\n",
        "---\n",
        "\n",
        "## ‚è±Ô∏è Estimated Time: 90 minutes\n",
        "\n",
        "---\n",
        "\n",
        "## Context\n",
        "\n",
        "**Scenario:** A vendor approaches your Australian health service with a deterioration prediction model. The model was developed and validated using data from large US academic medical centres. The vendor provides impressive performance statistics.\n",
        "\n",
        "**Your task:** Before recommending deployment, you must validate the model on your local patient population to determine whether the vendor's claimed performance translates to your setting.\n",
        "\n",
        "**Why this matters:**\n",
        "- Models trained on one population often perform worse on others\n",
        "- Different clinical practices, patient demographics, and data systems affect performance\n",
        "- Published or vendor-reported performance may not reflect your reality\n",
        "- Local validation is now considered essential before any AI deployment"
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setup and Load the \"Vendor\" Model"
      ],
      "metadata": {
        "id": "part1-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup - run this first!\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, \n",
        "    roc_auc_score, confusion_matrix, roc_curve,\n",
        "    precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.calibration import calibration_curve\n",
        "import pickle\n",
        "import io\n",
        "import base64\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate a \"vendor\" model trained on US data\n",
        "# In reality, you would receive this from the vendor\n",
        "\n",
        "def create_vendor_model():\n",
        "    \"\"\"\n",
        "    Create a simulated vendor model trained on US hospital data.\n",
        "    This represents what you might receive from a commercial vendor.\n",
        "    \"\"\"\n",
        "    np.random.seed(123)  # Different seed for \"US\" data\n",
        "    \n",
        "    # Generate \"US\" training data with slightly different characteristics\n",
        "    n_us = 5000\n",
        "    \n",
        "    us_data = pd.DataFrame({\n",
        "        'age': np.random.normal(58, 18, n_us).clip(18, 95).astype(int),  # Older population\n",
        "        'heart_rate': np.random.normal(82, 15, n_us).clip(40, 180).astype(int),\n",
        "        'respiratory_rate': np.random.normal(17, 4, n_us).clip(8, 40).astype(int),\n",
        "        'systolic_bp': np.random.normal(128, 20, n_us).clip(70, 200).astype(int),\n",
        "        'temperature_f': np.random.normal(98.6, 1.2, n_us).clip(95, 105),  # Fahrenheit!\n",
        "        'oxygen_saturation': np.random.normal(95, 4, n_us).clip(80, 100).astype(int),\n",
        "        'bmi': np.random.normal(29, 6, n_us).clip(15, 50),  # Higher BMI\n",
        "        'los_hours': np.random.exponential(24, n_us).clip(1, 200),\n",
        "    })\n",
        "    \n",
        "    # US outcome model (different risk factors)\n",
        "    us_risk = (\n",
        "        0.015 * (us_data['age'] - 50) / 10 +\n",
        "        0.008 * (us_data['heart_rate'] - 80) / 20 +\n",
        "        0.005 * (us_data['bmi'] - 25) / 5 +\n",
        "        -0.003 * (us_data['oxygen_saturation'] - 95) +\n",
        "        np.random.normal(0, 0.04, n_us)\n",
        "    )\n",
        "    us_outcomes = (us_risk > 0.12).astype(int)\n",
        "    \n",
        "    # Train the \"vendor\" model\n",
        "    features = ['age', 'heart_rate', 'respiratory_rate', 'systolic_bp', \n",
        "                'oxygen_saturation', 'bmi']\n",
        "    \n",
        "    model = GradientBoostingClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(us_data[features], us_outcomes)\n",
        "    \n",
        "    # Calculate \"vendor reported\" performance on US test data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        us_data[features], us_outcomes, test_size=0.2, random_state=42\n",
        "    )\n",
        "    y_prob = model.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    vendor_performance = {\n",
        "        'AUC': roc_auc_score(y_test, y_prob),\n",
        "        'Sensitivity': recall_score(y_test, model.predict(X_test)),\n",
        "        'Specificity': 1 - (model.predict(X_test)[y_test == 0].mean()),\n",
        "        'PPV': precision_score(y_test, model.predict(X_test)),\n",
        "        'N_development': len(X_train),\n",
        "        'N_validation': len(X_test)\n",
        "    }\n",
        "    \n",
        "    return model, features, vendor_performance\n",
        "\n",
        "# Create the vendor model\n",
        "vendor_model, expected_features, vendor_claimed = create_vendor_model()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"VENDOR MODEL SPECIFICATIONS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nModel Name: DeterioratePredict Pro v2.1\")\n",
        "print(f\"Vendor: HealthAI Solutions Inc.\")\n",
        "print(f\"Development Data: US Academic Medical Centres (2019-2023)\")\n",
        "print(f\"\\nModel Type: {type(vendor_model).__name__}\")\n",
        "print(f\"\\nRequired Input Features:\")\n",
        "for feat in expected_features:\n",
        "    print(f\"  ‚Ä¢ {feat}\")\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"VENDOR-CLAIMED PERFORMANCE (US Validation Cohort)\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nDevelopment cohort: n = {vendor_claimed['N_development']:,}\")\n",
        "print(f\"Validation cohort: n = {vendor_claimed['N_validation']:,}\")\n",
        "print(f\"\\nPerformance Metrics:\")\n",
        "print(f\"  AUC-ROC: {vendor_claimed['AUC']:.3f}\")\n",
        "print(f\"  Sensitivity: {vendor_claimed['Sensitivity']:.1%}\")\n",
        "print(f\"  Specificity: {vendor_claimed['Specificity']:.1%}\")\n",
        "print(f\"  PPV: {vendor_claimed['PPV']:.1%}\")"
      ],
      "metadata": {
        "id": "create-vendor-model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Prepare Local Australian Validation Data\n",
        "\n",
        "Now let's load your local hospital data and check compatibility with the vendor model."
      ],
      "metadata": {
        "id": "part2-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic Australian hospital data\n",
        "def generate_australian_data(n_patients=1000):\n",
        "    \"\"\"\n",
        "    Generate synthetic Australian hospital data with:\n",
        "    - Different demographic patterns\n",
        "    - Metric units (Celsius, not Fahrenheit)\n",
        "    - Australian-specific characteristics\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "    \n",
        "    # Demographics - Australian patterns\n",
        "    ages = np.random.normal(52, 22, n_patients).clip(18, 95).astype(int)  # Younger than US\n",
        "    \n",
        "    # Indigenous status (for later subgroup analysis)\n",
        "    indigenous = np.random.choice(\n",
        "        ['Non-Indigenous', 'Indigenous'],\n",
        "        n_patients,\n",
        "        p=[0.95, 0.05]\n",
        "    )\n",
        "    \n",
        "    # Remoteness\n",
        "    remoteness = np.random.choice(\n",
        "        ['Metropolitan', 'Regional', 'Remote'],\n",
        "        n_patients,\n",
        "        p=[0.70, 0.25, 0.05]\n",
        "    )\n",
        "    \n",
        "    # Clinical data - metric units, different baselines\n",
        "    data = pd.DataFrame({\n",
        "        'patient_id': [f'AU{i:05d}' for i in range(n_patients)],\n",
        "        'age': ages,\n",
        "        'indigenous_status': indigenous,\n",
        "        'remoteness': remoteness,\n",
        "        'heart_rate': np.random.normal(78, 16, n_patients).clip(40, 180).astype(int),\n",
        "        'respiratory_rate': np.random.normal(16, 5, n_patients).clip(8, 40).astype(int),\n",
        "        'systolic_bp': np.random.normal(122, 18, n_patients).clip(70, 200).astype(int),\n",
        "        'temperature_c': np.random.normal(37.0, 0.6, n_patients).clip(35, 41),  # Celsius!\n",
        "        'oxygen_saturation': np.random.normal(96, 3, n_patients).clip(80, 100).astype(int),\n",
        "        'bmi': np.random.normal(27, 5, n_patients).clip(15, 50),  # Lower than US\n",
        "        'comorbidity_count': np.random.poisson(1.2, n_patients).clip(0, 8),\n",
        "    })\n",
        "    \n",
        "    # Australian outcomes (different risk profile)\n",
        "    au_risk = (\n",
        "        0.012 * (data['age'] - 50) / 10 +\n",
        "        0.006 * (data['heart_rate'] - 78) / 20 +\n",
        "        0.008 * data['comorbidity_count'] +\n",
        "        -0.004 * (data['oxygen_saturation'] - 96) +\n",
        "        0.02 * (data['remoteness'] == 'Remote').astype(int) +\n",
        "        np.random.normal(0, 0.03, n_patients)\n",
        "    )\n",
        "    data['adverse_outcome'] = (au_risk > 0.10).astype(int)\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Generate local data\n",
        "au_data = generate_australian_data(1000)\n",
        "\n",
        "print(\"Local Australian Hospital Data Loaded\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total patients: {len(au_data):,}\")\n",
        "print(f\"Adverse outcome rate: {au_data['adverse_outcome'].mean()*100:.1f}%\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "au_data.head()"
      ],
      "metadata": {
        "id": "load-local-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data compatibility with vendor model\n",
        "print(\"=\"*60)\n",
        "print(\"DATA COMPATIBILITY CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nVendor model expects these features:\")\n",
        "for feat in expected_features:\n",
        "    print(f\"  ‚Ä¢ {feat}\")\n",
        "\n",
        "print(\"\\nLocal data columns:\")\n",
        "print(au_data.columns.tolist())\n",
        "\n",
        "# Check for missing/different features\n",
        "local_cols = set(au_data.columns)\n",
        "required = set(expected_features)\n",
        "\n",
        "missing = required - local_cols\n",
        "extra = local_cols - required\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è COMPATIBILITY ISSUES:\")\n",
        "if missing:\n",
        "    print(f\"  Missing required features: {missing}\")\n",
        "else:\n",
        "    print(f\"  No missing features ‚úì\")\n",
        "\n",
        "# Check for unit differences\n",
        "print(\"\\n‚ö†Ô∏è POTENTIAL UNIT MISMATCH:\")\n",
        "print(\"  Local data has 'temperature_c' (Celsius)\")\n",
        "print(\"  Vendor model likely expects Fahrenheit\")\n",
        "print(\"  ‚ûú Conversion may be required!\")"
      ],
      "metadata": {
        "id": "compatibility-check"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare local data for the vendor model\n",
        "print(\"Preparing local data for vendor model...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Create a copy for model input\n",
        "au_model_data = au_data.copy()\n",
        "\n",
        "# Handle missing/different features\n",
        "# Note: We'll use the features the vendor expects, not temperature\n",
        "# This simulates real-world data compatibility challenges\n",
        "\n",
        "# Check we have the required features\n",
        "model_features = au_model_data[['age', 'heart_rate', 'respiratory_rate', \n",
        "                                 'systolic_bp', 'oxygen_saturation', 'bmi']]\n",
        "\n",
        "print(f\"\\nPrepared {len(model_features)} patients for validation\")\n",
        "print(f\"Using features: {model_features.columns.tolist()}\")\n",
        "print(\"\\n‚úÖ Data prepared for vendor model\")"
      ],
      "metadata": {
        "id": "prepare-data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Compare Populations\n",
        "\n",
        "Before validating, let's understand how our local population differs from the vendor's development population."
      ],
      "metadata": {
        "id": "part3-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare population characteristics\n",
        "print(\"=\"*60)\n",
        "print(\"POPULATION COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Recreate US summary stats for comparison\n",
        "us_summary = {\n",
        "    'Age (mean)': '58 years',\n",
        "    'Age (SD)': '18 years',\n",
        "    'Heart Rate (mean)': '82 bpm',\n",
        "    'BMI (mean)': '29 kg/m¬≤',\n",
        "    'SpO2 (mean)': '95%',\n",
        "    'Outcome Rate': '~18%'\n",
        "}\n",
        "\n",
        "au_summary = {\n",
        "    'Age (mean)': f\"{au_data['age'].mean():.0f} years\",\n",
        "    'Age (SD)': f\"{au_data['age'].std():.0f} years\",\n",
        "    'Heart Rate (mean)': f\"{au_data['heart_rate'].mean():.0f} bpm\",\n",
        "    'BMI (mean)': f\"{au_data['bmi'].mean():.1f} kg/m¬≤\",\n",
        "    'SpO2 (mean)': f\"{au_data['oxygen_saturation'].mean():.0f}%\",\n",
        "    'Outcome Rate': f\"{au_data['adverse_outcome'].mean()*100:.1f}%\"\n",
        "}\n",
        "\n",
        "comparison = pd.DataFrame({\n",
        "    'US (Vendor Data)': us_summary,\n",
        "    'Australian (Local)': au_summary\n",
        "})\n",
        "\n",
        "print(\"\\n\" + comparison.to_string())\n",
        "\n",
        "print(\"\\nüí° Key Differences:\")\n",
        "print(\"  ‚Ä¢ Australian patients are younger on average\")\n",
        "print(\"  ‚Ä¢ Australian BMI is lower than US\")\n",
        "print(\"  ‚Ä¢ Baseline outcome rates may differ\")\n",
        "print(\"  ‚Ä¢ These differences may affect model performance!\")"
      ],
      "metadata": {
        "id": "compare-populations"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise population differences\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# Simulate US distributions for comparison\n",
        "np.random.seed(123)\n",
        "us_ages = np.random.normal(58, 18, 1000).clip(18, 95)\n",
        "us_bmi = np.random.normal(29, 6, 1000).clip(15, 50)\n",
        "us_hr = np.random.normal(82, 15, 1000).clip(40, 180)\n",
        "us_spo2 = np.random.normal(95, 4, 1000).clip(80, 100)\n",
        "\n",
        "# Age comparison\n",
        "axes[0, 0].hist(us_ages, bins=20, alpha=0.6, label='US (Vendor)', color='steelblue')\n",
        "axes[0, 0].hist(au_data['age'], bins=20, alpha=0.6, label='Australian (Local)', color='coral')\n",
        "axes[0, 0].set_xlabel('Age (years)')\n",
        "axes[0, 0].set_ylabel('Count')\n",
        "axes[0, 0].set_title('Age Distribution')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# BMI comparison\n",
        "axes[0, 1].hist(us_bmi, bins=20, alpha=0.6, label='US (Vendor)', color='steelblue')\n",
        "axes[0, 1].hist(au_data['bmi'], bins=20, alpha=0.6, label='Australian (Local)', color='coral')\n",
        "axes[0, 1].set_xlabel('BMI (kg/m¬≤)')\n",
        "axes[0, 1].set_ylabel('Count')\n",
        "axes[0, 1].set_title('BMI Distribution')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# Heart rate comparison\n",
        "axes[1, 0].hist(us_hr, bins=20, alpha=0.6, label='US (Vendor)', color='steelblue')\n",
        "axes[1, 0].hist(au_data['heart_rate'], bins=20, alpha=0.6, label='Australian (Local)', color='coral')\n",
        "axes[1, 0].set_xlabel('Heart Rate (bpm)')\n",
        "axes[1, 0].set_ylabel('Count')\n",
        "axes[1, 0].set_title('Heart Rate Distribution')\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# SpO2 comparison\n",
        "axes[1, 1].hist(us_spo2, bins=20, alpha=0.6, label='US (Vendor)', color='steelblue')\n",
        "axes[1, 1].hist(au_data['oxygen_saturation'], bins=20, alpha=0.6, label='Australian (Local)', color='coral')\n",
        "axes[1, 1].set_xlabel('SpO2 (%)')\n",
        "axes[1, 1].set_ylabel('Count')\n",
        "axes[1, 1].set_title('Oxygen Saturation Distribution')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è Population shift detected! This is a form of 'dataset shift'\")\n",
        "print(\"   that commonly causes AI models to underperform when deployed.\")"
      ],
      "metadata": {
        "id": "visualise-populations"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: External Validation\n",
        "\n",
        "Now let's run the vendor model on our local data and compare performance."
      ],
      "metadata": {
        "id": "part4-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run vendor model on local data\n",
        "print(\"Running vendor model on local Australian data...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Get predictions\n",
        "X_local = au_data[expected_features]\n",
        "y_local = au_data['adverse_outcome']\n",
        "\n",
        "# Predictions and probabilities\n",
        "local_predictions = vendor_model.predict(X_local)\n",
        "local_probabilities = vendor_model.predict_proba(X_local)[:, 1]\n",
        "\n",
        "# Calculate local performance metrics\n",
        "local_performance = {\n",
        "    'AUC': roc_auc_score(y_local, local_probabilities),\n",
        "    'Sensitivity': recall_score(y_local, local_predictions),\n",
        "    'Specificity': 1 - local_predictions[y_local == 0].mean(),\n",
        "    'PPV': precision_score(y_local, local_predictions),\n",
        "    'N': len(y_local)\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Validation complete!\")"
      ],
      "metadata": {
        "id": "run-validation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare vendor claimed vs local validated performance\n",
        "print(\"=\"*70)\n",
        "print(\"PERFORMANCE COMPARISON: VENDOR CLAIMED vs LOCAL VALIDATED\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "comparison_metrics = ['AUC', 'Sensitivity', 'Specificity', 'PPV']\n",
        "\n",
        "print(f\"\\n{'Metric':<15} {'Vendor (US)':<15} {'Local (AU)':<15} {'Difference':<15}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "performance_gaps = {}\n",
        "for metric in comparison_metrics:\n",
        "    vendor_val = vendor_claimed[metric]\n",
        "    local_val = local_performance[metric]\n",
        "    diff = local_val - vendor_val\n",
        "    performance_gaps[metric] = diff\n",
        "    \n",
        "    # Color code the difference\n",
        "    diff_str = f\"{diff:+.3f}\"\n",
        "    if diff < -0.05:\n",
        "        diff_str += \" ‚ö†Ô∏è\"\n",
        "    elif diff < -0.10:\n",
        "        diff_str += \" üî¥\"\n",
        "    \n",
        "    print(f\"{metric:<15} {vendor_val:<15.3f} {local_val:<15.3f} {diff_str:<15}\")\n",
        "\n",
        "print(\"\\n\" + \"-\" * 60)\n",
        "print(f\"Vendor validation N: {vendor_claimed['N_validation']:,}\")\n",
        "print(f\"Local validation N: {local_performance['N']:,}\")"
      ],
      "metadata": {
        "id": "compare-performance"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise the performance gap\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart comparison\n",
        "x = np.arange(len(comparison_metrics))\n",
        "width = 0.35\n",
        "\n",
        "vendor_vals = [vendor_claimed[m] for m in comparison_metrics]\n",
        "local_vals = [local_performance[m] for m in comparison_metrics]\n",
        "\n",
        "bars1 = axes[0].bar(x - width/2, vendor_vals, width, label='Vendor (US)', color='steelblue')\n",
        "bars2 = axes[0].bar(x + width/2, local_vals, width, label='Local (AU)', color='coral')\n",
        "\n",
        "axes[0].set_xlabel('Metric')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('Performance: Vendor Claimed vs Local Validated')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(comparison_metrics)\n",
        "axes[0].legend()\n",
        "axes[0].set_ylim(0, 1)\n",
        "axes[0].axhline(0.8, color='green', linestyle='--', alpha=0.5, label='Acceptable threshold')\n",
        "\n",
        "# ROC curve comparison (local only - we don't have US raw data)\n",
        "fpr, tpr, _ = roc_curve(y_local, local_probabilities)\n",
        "axes[1].plot(fpr, tpr, 'coral', linewidth=2, \n",
        "             label=f'Local AUC = {local_performance[\"AUC\"]:.3f}')\n",
        "axes[1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "axes[1].fill_between(fpr, tpr, alpha=0.3, color='coral')\n",
        "axes[1].set_xlabel('False Positive Rate')\n",
        "axes[1].set_ylabel('True Positive Rate')\n",
        "axes[1].set_title(f'Local Validation ROC Curve\\n(Vendor claimed AUC: {vendor_claimed[\"AUC\"]:.3f})')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary interpretation\n",
        "auc_gap = performance_gaps['AUC']\n",
        "if auc_gap < -0.10:\n",
        "    print(\"\\nüî¥ SIGNIFICANT PERFORMANCE DEGRADATION DETECTED\")\n",
        "    print(f\"   AUC dropped by {abs(auc_gap):.3f} from vendor claims\")\n",
        "elif auc_gap < -0.05:\n",
        "    print(\"\\n‚ö†Ô∏è MODERATE PERFORMANCE DEGRADATION DETECTED\")\n",
        "    print(f\"   AUC dropped by {abs(auc_gap):.3f} from vendor claims\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ Performance reasonably consistent with vendor claims\")"
      ],
      "metadata": {
        "id": "visualise-gap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Subgroup Analysis\n",
        "\n",
        "Does the model perform consistently across different patient subgroups in our local population?"
      ],
      "metadata": {
        "id": "part5-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add predictions to dataframe for subgroup analysis\n",
        "au_data['predicted'] = local_predictions\n",
        "au_data['probability'] = local_probabilities\n",
        "\n",
        "def subgroup_performance(df, group_column):\n",
        "    \"\"\"Calculate performance metrics by subgroup.\"\"\"\n",
        "    results = []\n",
        "    for group in df[group_column].unique():\n",
        "        subset = df[df[group_column] == group]\n",
        "        if len(subset) < 20:\n",
        "            continue\n",
        "        \n",
        "        y_true = subset['adverse_outcome']\n",
        "        y_pred = subset['predicted']\n",
        "        y_prob = subset['probability']\n",
        "        \n",
        "        try:\n",
        "            auc = roc_auc_score(y_true, y_prob)\n",
        "        except:\n",
        "            auc = np.nan\n",
        "            \n",
        "        results.append({\n",
        "            'Group': group,\n",
        "            'N': len(subset),\n",
        "            'Outcome Rate': y_true.mean(),\n",
        "            'AUC': auc,\n",
        "            'Sensitivity': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'PPV': precision_score(y_true, y_pred, zero_division=0)\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Analyse by remoteness\n",
        "print(\"=\"*60)\n",
        "print(\"SUBGROUP ANALYSIS: BY REMOTENESS\")\n",
        "print(\"=\"*60)\n",
        "remoteness_perf = subgroup_performance(au_data, 'remoteness')\n",
        "print(remoteness_perf.round(3).to_string(index=False))"
      ],
      "metadata": {
        "id": "subgroup-remoteness"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyse by Indigenous status\n",
        "print(\"=\"*60)\n",
        "print(\"SUBGROUP ANALYSIS: BY INDIGENOUS STATUS\")\n",
        "print(\"=\"*60)\n",
        "indigenous_perf = subgroup_performance(au_data, 'indigenous_status')\n",
        "print(indigenous_perf.round(3).to_string(index=False))\n",
        "\n",
        "# Calculate disparity\n",
        "if len(indigenous_perf) > 1:\n",
        "    sens_values = indigenous_perf.set_index('Group')['Sensitivity']\n",
        "    if 'Indigenous' in sens_values.index and 'Non-Indigenous' in sens_values.index:\n",
        "        gap = sens_values['Non-Indigenous'] - sens_values['Indigenous']\n",
        "        print(f\"\\n‚ö†Ô∏è Sensitivity gap: {gap*100:+.1f} percentage points\")"
      ],
      "metadata": {
        "id": "subgroup-indigenous"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create age groups for analysis\n",
        "au_data['age_group'] = pd.cut(au_data['age'], \n",
        "                               bins=[0, 40, 60, 80, 100],\n",
        "                               labels=['<40', '40-60', '60-80', '80+'])\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SUBGROUP ANALYSIS: BY AGE GROUP\")\n",
        "print(\"=\"*60)\n",
        "age_perf = subgroup_performance(au_data, 'age_group')\n",
        "print(age_perf.round(3).to_string(index=False))"
      ],
      "metadata": {
        "id": "subgroup-age"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualise subgroup performance\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# By remoteness\n",
        "rem_sorted = remoteness_perf.sort_values('AUC', ascending=True)\n",
        "axes[0].barh(rem_sorted['Group'], rem_sorted['AUC'], color='steelblue')\n",
        "axes[0].axvline(local_performance['AUC'], color='red', linestyle='--', label='Overall')\n",
        "axes[0].axvline(vendor_claimed['AUC'], color='green', linestyle='--', label='Vendor claim')\n",
        "axes[0].set_xlabel('AUC')\n",
        "axes[0].set_title('AUC by Remoteness')\n",
        "axes[0].legend()\n",
        "axes[0].set_xlim(0.5, 1.0)\n",
        "\n",
        "# By Indigenous status\n",
        "ind_sorted = indigenous_perf.sort_values('AUC', ascending=True)\n",
        "axes[1].barh(ind_sorted['Group'], ind_sorted['AUC'], color='steelblue')\n",
        "axes[1].axvline(local_performance['AUC'], color='red', linestyle='--', label='Overall')\n",
        "axes[1].axvline(vendor_claimed['AUC'], color='green', linestyle='--', label='Vendor claim')\n",
        "axes[1].set_xlabel('AUC')\n",
        "axes[1].set_title('AUC by Indigenous Status')\n",
        "axes[1].legend()\n",
        "axes[1].set_xlim(0.5, 1.0)\n",
        "\n",
        "# By age group\n",
        "age_sorted = age_perf.sort_values('AUC', ascending=True)\n",
        "axes[2].barh(age_sorted['Group'].astype(str), age_sorted['AUC'], color='steelblue')\n",
        "axes[2].axvline(local_performance['AUC'], color='red', linestyle='--', label='Overall')\n",
        "axes[2].axvline(vendor_claimed['AUC'], color='green', linestyle='--', label='Vendor claim')\n",
        "axes[2].set_xlabel('AUC')\n",
        "axes[2].set_title('AUC by Age Group')\n",
        "axes[2].legend()\n",
        "axes[2].set_xlim(0.5, 1.0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Subgroup analysis reveals whether the model works for ALL your patients,\")\n",
        "print(\"   not just the 'average' patient.\")"
      ],
      "metadata": {
        "id": "visualise-subgroups"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Calibration Analysis\n",
        "\n",
        "Even if the model discriminates well (high AUC), are its probability estimates accurate?"
      ],
      "metadata": {
        "id": "part6-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calibration analysis\n",
        "print(\"=\"*60)\n",
        "print(\"CALIBRATION ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calculate calibration curve\n",
        "prob_true, prob_pred = calibration_curve(y_local, local_probabilities, n_bins=10)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Calibration plot\n",
        "axes[0].plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n",
        "axes[0].plot(prob_pred, prob_true, 'o-', color='coral', label='Model')\n",
        "axes[0].set_xlabel('Mean Predicted Probability')\n",
        "axes[0].set_ylabel('Fraction of Positives')\n",
        "axes[0].set_title('Calibration Curve')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Prediction distribution\n",
        "axes[1].hist(local_probabilities[y_local == 0], bins=20, alpha=0.6, \n",
        "             label='No deterioration', color='steelblue')\n",
        "axes[1].hist(local_probabilities[y_local == 1], bins=20, alpha=0.6,\n",
        "             label='Deterioration', color='coral')\n",
        "axes[1].set_xlabel('Predicted Probability')\n",
        "axes[1].set_ylabel('Count')\n",
        "axes[1].set_title('Distribution of Predicted Probabilities')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Calibration Interpretation:\")\n",
        "print(\"  ‚Ä¢ If the model predicts 30% probability, ~30% of those patients\")\n",
        "print(\"    should actually deteriorate if well-calibrated\")\n",
        "print(\"  ‚Ä¢ Poor calibration means probability estimates are unreliable\")\n",
        "print(\"  ‚Ä¢ May need recalibration before deployment\")"
      ],
      "metadata": {
        "id": "calibration"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 7: Go/No-Go Decision Framework\n",
        "\n",
        "Based on your validation, complete the decision framework for governance."
      ],
      "metadata": {
        "id": "part7-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate validation report\n",
        "print(\"=\"*70)\n",
        "print(\"LOCAL VALIDATION REPORT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "validation_report = {\n",
        "    'Model Name': 'DeterioratePredict Pro v2.1',\n",
        "    'Vendor': 'HealthAI Solutions Inc.',\n",
        "    'Validation Date': '2024-XX-XX',\n",
        "    'Local Sample Size': len(au_data),\n",
        "    'Validation Setting': 'Australian Regional Hospital',\n",
        "    '---': '---',\n",
        "    'Vendor Claimed AUC': f\"{vendor_claimed['AUC']:.3f}\",\n",
        "    'Local Validated AUC': f\"{local_performance['AUC']:.3f}\",\n",
        "    'Performance Gap': f\"{performance_gaps['AUC']:+.3f}\",\n",
        "    '----': '----',\n",
        "    'Vendor Claimed Sensitivity': f\"{vendor_claimed['Sensitivity']:.1%}\",\n",
        "    'Local Validated Sensitivity': f\"{local_performance['Sensitivity']:.1%}\",\n",
        "    'Sensitivity Gap': f\"{performance_gaps['Sensitivity']*100:+.1f}%\",\n",
        "}\n",
        "\n",
        "for key, value in validation_report.items():\n",
        "    if key.startswith('-'):\n",
        "        print(\"-\" * 50)\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# Decision criteria\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DECISION CRITERIA ASSESSMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "criteria = [\n",
        "    ('AUC ‚â• 0.75', local_performance['AUC'] >= 0.75),\n",
        "    ('Sensitivity ‚â• 70%', local_performance['Sensitivity'] >= 0.70),\n",
        "    ('AUC gap ‚â§ 0.10 from vendor', abs(performance_gaps['AUC']) <= 0.10),\n",
        "    ('No subgroup AUC < 0.70', all(remoteness_perf['AUC'].dropna() >= 0.70)),\n",
        "]\n",
        "\n",
        "print(f\"\\n{'Criterion':<40} {'Met?':<10}\")\n",
        "print(\"-\" * 50)\n",
        "all_met = True\n",
        "for criterion, met in criteria:\n",
        "    status = \"‚úÖ Yes\" if met else \"‚ùå No\"\n",
        "    if not met:\n",
        "        all_met = False\n",
        "    print(f\"{criterion:<40} {status:<10}\")"
      ],
      "metadata": {
        "id": "validation-report"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision framework\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GO / NO-GO DECISION FRAMEWORK\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if all_met:\n",
        "    recommendation = \"CONDITIONAL GO\"\n",
        "    color = \"üü°\"\n",
        "elif local_performance['AUC'] < 0.70:\n",
        "    recommendation = \"NO-GO\"\n",
        "    color = \"üî¥\"\n",
        "else:\n",
        "    recommendation = \"DEFER - Further evaluation required\"\n",
        "    color = \"üü†\"\n",
        "\n",
        "print(f\"\\n{color} RECOMMENDATION: {recommendation}\")\n",
        "\n",
        "print(\"\\nConditions for deployment (if approved):\")\n",
        "conditions = [\n",
        "    \"1. 3-month silent running period before clinical use\",\n",
        "    \"2. Mandatory clinical override capability\",\n",
        "    \"3. Weekly performance monitoring by subgroup\",\n",
        "    \"4. Clear escalation pathway for performance degradation\",\n",
        "    \"5. Staff training on model limitations\",\n",
        "    \"6. Patient notification that AI is being used\"\n",
        "]\n",
        "\n",
        "for condition in conditions:\n",
        "    print(f\"  {condition}\")\n",
        "\n",
        "print(\"\\nQuestions for vendor:\")\n",
        "questions = [\n",
        "    \"1. Why does performance differ in Australian population?\",\n",
        "    \"2. Can model be recalibrated on local data?\",\n",
        "    \"3. What ongoing support is provided?\",\n",
        "    \"4. How often is the model updated?\",\n",
        "    \"5. What liability does vendor accept for failures?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    print(f\"  {question}\")"
      ],
      "metadata": {
        "id": "decision-framework"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 8: Your Validation Report\n",
        "\n",
        "Complete the validation report template below for governance submission."
      ],
      "metadata": {
        "id": "part8-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== YOUR VALIDATION REPORT =====\n",
        "\n",
        "your_report = \"\"\"\n",
        "============================================================\n",
        "LOCAL VALIDATION REPORT FOR CLINICAL GOVERNANCE\n",
        "============================================================\n",
        "\n",
        "AI SYSTEM: DeterioratePredict Pro v2.1\n",
        "VENDOR: HealthAI Solutions Inc.\n",
        "EVALUATOR: [Your name]\n",
        "DATE: [Date]\n",
        "VALIDATION SETTING: [Your health service]\n",
        "\n",
        "------------------------------------------------------------\n",
        "1. EXECUTIVE SUMMARY\n",
        "------------------------------------------------------------\n",
        "[2-3 sentence summary of validation findings and recommendation]\n",
        "\n",
        "\n",
        "\n",
        "------------------------------------------------------------\n",
        "2. PERFORMANCE COMPARISON\n",
        "------------------------------------------------------------\n",
        "\n",
        "Metric          Vendor (US)    Local (AU)    Gap\n",
        "-------         -----------    ----------    ---\n",
        "AUC             [value]        [value]       [value]\n",
        "Sensitivity     [value]        [value]       [value]\n",
        "Specificity     [value]        [value]       [value]\n",
        "\n",
        "------------------------------------------------------------\n",
        "3. SUBGROUP ANALYSIS\n",
        "------------------------------------------------------------\n",
        "[Describe any concerning disparities by subgroup]\n",
        "\n",
        "\n",
        "\n",
        "------------------------------------------------------------\n",
        "4. POPULATION DIFFERENCES\n",
        "------------------------------------------------------------\n",
        "[Key differences between vendor development population and local]\n",
        "\n",
        "\n",
        "\n",
        "------------------------------------------------------------\n",
        "5. RECOMMENDATION\n",
        "------------------------------------------------------------\n",
        "[ ] APPROVE for deployment\n",
        "[ ] APPROVE with conditions\n",
        "[ ] DEFER pending [specify]\n",
        "[ ] DO NOT APPROVE\n",
        "\n",
        "Rationale:\n",
        "\n",
        "\n",
        "\n",
        "------------------------------------------------------------\n",
        "6. CONDITIONS FOR DEPLOYMENT (if applicable)\n",
        "------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "------------------------------------------------------------\n",
        "7. MONITORING PLAN\n",
        "------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "============================================================\n",
        "\"\"\"\n",
        "\n",
        "print(your_report)"
      ],
      "metadata": {
        "id": "your-report"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 9: Reflection Questions"
      ],
      "metadata": {
        "id": "reflection-intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== YOUR REFLECTIONS =====\n",
        "\n",
        "reflections = \"\"\"\n",
        "1. How much performance degradation from vendor claims is acceptable?\n",
        "   What if AUC drops from 0.85 to 0.78? To 0.72? Where's the line?\n",
        "   Your answer:\n",
        "   \n",
        "\n",
        "2. If the model works well overall but poorly for Indigenous patients\n",
        "   or remote populations, should you still deploy it?\n",
        "   Your answer:\n",
        "   \n",
        "\n",
        "3. What additional information would you want from the vendor before\n",
        "   making a final decision?\n",
        "   Your answer:\n",
        "   \n",
        "\n",
        "4. What would 'silent running' look like in your clinical setting?\n",
        "   How would you monitor performance without affecting care?\n",
        "   Your answer:\n",
        "   \n",
        "\n",
        "5. If you had to explain this validation to a patient, what would\n",
        "   you tell them?\n",
        "   Your answer:\n",
        "   \n",
        "\n",
        "\"\"\"\n",
        "\n",
        "print(reflections)"
      ],
      "metadata": {
        "id": "reflections"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìù Deliverable\n",
        "\n",
        "**For your portfolio:**\n",
        "\n",
        "Complete the validation report (Part 8) as if you were submitting it to your clinical governance committee. Include:\n",
        "\n",
        "1. Performance comparison (vendor vs local)\n",
        "2. Subgroup analysis findings\n",
        "3. Clear go/no-go recommendation with rationale\n",
        "4. Conditions for deployment (if recommending approval)\n",
        "5. Monitoring plan\n",
        "\n",
        "Submit via LMS by the Week 7 deadline."
      ],
      "metadata": {
        "id": "deliverable"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üèÅ Summary\n",
        "\n",
        "In this exercise, you learned:\n",
        "\n",
        "‚úÖ **Local validation is essential** - vendor performance rarely translates directly\n",
        "\n",
        "‚úÖ **Population differences matter** - age, demographics, clinical practice all affect performance\n",
        "\n",
        "‚úÖ **Subgroup analysis reveals hidden failures** - overall performance can mask disparities\n",
        "\n",
        "‚úÖ **Calibration affects clinical utility** - probability estimates may need adjustment\n",
        "\n",
        "‚úÖ **Structured frameworks support decisions** - governance needs clear criteria\n",
        "\n",
        "**Key takeaway:** Never deploy a vendor AI without local validation. \"Validated\" elsewhere doesn't mean validated here.\n",
        "\n",
        "---\n",
        "\n",
        "**Next exercise (Week 10):** We'll experiment with large language models (LLMs) for clinical applications."
      ],
      "metadata": {
        "id": "summary"
      }
    }
  ]
}
